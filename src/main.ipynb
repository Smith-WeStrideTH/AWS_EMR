{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Covid 19 Search Engine\n",
    "\n",
    "- **Goal**: Create a search engine that uses EMR Serverless for ad-hoc processing of larges amount of unstructured textual data\n",
    "- **Who is this course for?**: Anyone with background in Python programing and some knowledge of Spark and EMR willing to connect a practical application of ML and Data Engineering\n",
    "- **Data is available here**: https://www.kaggle.com/datasets/allen-institute-for-ai/CORD-19-research-challenge?datasetId=551982&sortBy=voteCount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How search engines works?\n",
    "- Benefits of Serverless Architecture\n",
    "- Code and Data Overview\n",
    "- Spark Processing Pipeline\n",
    "- Submitting EMR Job\n",
    "- Crawling data \n",
    "- Athena Table\n",
    "- Running Search Engine\n",
    "- Production Ready Code Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How (Modern) Search Engines works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Information Retrieval**: finding material (usually documents) of an unstructured nature (usually text) that satisfies an information need from within large collections (usually stored on computers)\n",
    "- **Term-based Retrieval Methods**: Mathematical framework defining query-document matching based on exact syntactic matching between a document and a query to estimate the relevance of documents given a search query.\n",
    "- **Usage**: Internet Search (Google, Bing etc), Smart Devices (Alexa, Google Assistant), Web shopping and etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Term Based Search Engines: BM25 (TF-IDF)\n",
    "![Image of BM25](https://miro.medium.com/max/720/1*V8zEF3m21WkJ-UYzME6cKA.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improving Search Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Removing Stop Words\n",
    "- Filtering unwanted text\n",
    "- Removal of Duplicates\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to process high volumes of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Distributed Computing**: Modern data engineering allows seamless horizontal scaling through frameworks like Hadoop and Spark\n",
    "- **In Memory Processing**: Usually limited to a single machine, uses ephemeral memory such as ram to perform computations faster\n",
    "- **SQL and NoSQL database**: Using specific query languages to manipulate structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clusters are expensive and hard to maintain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Setting up clusters for Hadoop and Spark is costly\n",
    "- Depending on the application, cluster will spend most of the time idle\n",
    "- On-going updates and maintance requires dedicated people\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the power of serverless architecture for data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Image of BM25](https://d1.awsstatic.com/Product-Page-Diagram_Amazon-EMR-Serverless%402x.d462590cd415fe4022e8644cf487f01c7a5f3f15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import shutil\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import awswrangler as wrangler\n",
    "from pyspark.sql.dataframe import DataFrame as SparkDataframe\n",
    "from pyspark.sql.functions import col, isnull, when, length, lit, coalesce, regexp_replace, to_date\n",
    "\n",
    "from src.processing import athena\n",
    "from src.processing.spark import get_spark_session, from_files\n",
    "from src.search import engine, results\n",
    "from src.processing.emr import EMRServerless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading Data into Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this section we will show step by step what each node of our Spark Direct Acyclic Graph (DAG) is doing. In order to use the data for a search engine we want to perform some cleaning and feature calculation to make it easier for our end user to use the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reading data from local, download the data from: \n",
    "\n",
    "https://www.kaggle.com/datasets/allen-institute-for-ai/CORD-19-research-challenge?datasetId=551982&sortBy=voteCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Getting the Spark Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "def get_spark_session(env: str = None, app_name: str = 'SparkApp') -> SparkSession:\n",
    "    if env is not None and env == 'DEV':\n",
    "        spark = (SparkSession\n",
    "                 .builder\n",
    "                 .master('local[*]')\n",
    "                 .appName(app_name)\n",
    "                 .getOrCreate())\n",
    "    else:\n",
    "        spark = (SparkSession\n",
    "                 .builder\n",
    "                 .appName(app_name)\n",
    "                 .getOrCreate())\n",
    "    return spark\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spark_session = get_spark_session(env='DEV', app_name='COVID-19 Research papers dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Configuring some of the spark context to have a cleaner Jupyter Notebook experience :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "spark_session.sparkContext.setLogLevel('error') # setting the log level to log error only\n",
    "log4jLogger = spark_session._jvm.org.apache.log4j\n",
    "logger = log4jLogger.LogManager.getLogger(__name__)\n",
    "logger.warn(f\"Pyspark script logger initialized from {__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We set a small sample amount to process just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_SEED = 1234\n",
    "SAMPLE_AMOUNT = 0.01 # Randomly Sample 1% of the data\n",
    "INPUT_PATH = '/Users/rpossas/Dev/workspace/data/Covid-19-Patient-Health-Analytics/metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = from_files(spark=spark_session, data_dir=INPUT_PATH, file_format=\"CSV\").sample(SAMPLE_AMOUNT, seed=SAMPLE_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will only be interested in a few columns, filtering the dataframe for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "INITIAL_COLUMNS = ('title','abstract','publish_time','authors','url')\n",
    "df = df.select(list(INITIAL_COLUMNS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lets have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.toPandas().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Cleaning and Processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Cleaning title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Cleans and removes junk titles, which are filtered according to the regex provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def clean_title(spark_df: SparkDataframe, relevant_regex: str = None) -> SparkDataframe:\n",
    "    \"\"\"\n",
    "    Cleans and removes junk titles, which are filtered according to the regex provided\n",
    "    :param spark_df: Spark Dataframe\n",
    "    :param relevant_regex: Regex that is used to filter relevant titles\n",
    "    :return: Filtered Dataframe\n",
    "    \"\"\"\n",
    "    if relevant_regex is None:\n",
    "        relevant_regex = '.*vir.*|.*sars.*|.*mers.*|.*corona.*|.*ncov.*|.*immun.*|.*nosocomial.*'\n",
    "        relevant_regex = relevant_regex + '.*epidem.*|.*emerg.*|.*vacc.*|.*cytokine.*'\n",
    "\n",
    "    is_title_junk = (length(col('title')) < 30) & ~(col('title').rlike(relevant_regex))\n",
    "    spark_df = spark_df.na.fill('', ['title'])\n",
    "    spark_df = spark_df.withColumn('title', when(is_title_junk, lit('')).otherwise(col('title')))\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = clean_title(spark_df=df)\n",
    "df.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Cleaning Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We perform the following operations\n",
    "\n",
    "- Remove any unused word from the provided regex\n",
    "- Replace Unknown Abstracts by None\n",
    "- Replace blank abstracts by the Title\n",
    "- Drop Duplicate Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def clean_abstract(spark_df: SparkDataframe, abstract_regex: str = None) -> SparkDataframe:\n",
    "    \"\"\"\n",
    "    Removes unused words and filters abstracts\n",
    "    :param spark_df: Spark Dataframe\n",
    "    :param abstract_regex: Regex of words to be removed from abstract\n",
    "    :return: Spark Dataframe\n",
    "    \"\"\"\n",
    "    if abstract_regex is None:\n",
    "        abstract_regex = '(Publisher|Abstract|Summary|BACKGROUND|INTRODUCTION)'\n",
    "\n",
    "    spark_df = spark_df.withColumn('abstract',\n",
    "                                   when(col('abstract') == 'Unknown', lit(None))\n",
    "                                   .otherwise(col('abstract')))\n",
    "    spark_df = spark_df.withColumn('abstract', coalesce('abstract', 'title')) # Replace empty abstracts by the title\n",
    "    spark_df = spark_df.withColumn('abstract', regexp_replace('abstract', abstract_regex, ''))\n",
    "    spark_df = spark_df.drop_duplicates(['abstract'])\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = clean_abstract(spark_df=df)\n",
    "df.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Tagging Key Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "SARS_COV_2_DATE = '2019-11-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Virus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def tag_virus(spark_df: SparkDataframe,\n",
    "              abstract_column='abstract',\n",
    "              virus_search: str = None) -> SparkDataframe:\n",
    "    \"\"\"\n",
    "    Creates a new column that indicates whether the article is about viruses\n",
    "    :param spark_df: Spark Dataframe\n",
    "    :param abstract_column: Text column to search for references\n",
    "    :param virus_search: regular expression to be applied\n",
    "    :return: Dataframe with new boolean column indicating presence of virus terms\n",
    "    \"\"\"\n",
    "    if virus_search is None:\n",
    "        virus_search = f\".*(virus|viruses|viral)\"\n",
    "    viral_cond = col(abstract_column).rlike(virus_search)\n",
    "    return spark_df.withColumn('virus_related', coalesce(viral_cond, lit(False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Coronavirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def tag_coronavirus(spark_df: SparkDataframe, abstract_column='abstract', corona_regex: str = None):\n",
    "    \"\"\"\n",
    "    Creates a column that indicates whether the article is about coronavirus\n",
    "    :param spark_df: Spork Dataframe\n",
    "    :param abstract_column: Text column to search for terms\n",
    "    :param corona_regex: Regular expression to be applied\n",
    "    :return: Dataframe with new boolean column indicating presence of coronavirus terms\n",
    "    \"\"\"\n",
    "    if corona_regex is None:\n",
    "        corona_regex = col(abstract_column).rlike(\".*corona\")\n",
    "    return spark_df.withColumn('corona_related', coalesce(corona_regex, lit(False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### SARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def tag_sars(spark_df: SparkDataframe, abstract_column='abstract', sars_regex: str = None):\n",
    "    \"\"\"\n",
    "    Creates a column that indicates whether the article is about sars\n",
    "    :param spark_df: Spork Dataframe\n",
    "    :param abstract_column: Text column to search for terms\n",
    "    :param sars_regex: Regular expression to be applied\n",
    "    :return: Dataframe with new boolean column indicating presence of coronavirus terms\n",
    "    \"\"\"\n",
    "    if sars_regex is None:\n",
    "        sars_regex = \".*sars\"\n",
    "\n",
    "    sars_cond = col(abstract_column).rlike(sars_regex)\n",
    "    sars_not_covid = ~(col('covid_related')) & (sars_cond)\n",
    "    return spark_df.withColumn('sars_related', coalesce(sars_not_covid, lit(False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def tag_covid(spark_df: SparkDataframe,\n",
    "              date_column: str = 'publish_time',\n",
    "              abstract_column: str = 'abstract',\n",
    "              covid_terms: str = None):\n",
    "    \"\"\"\n",
    "    Creates a boolean column to flag whether the article is about COVID\n",
    "    :param spark_df: Spark Dataframe\n",
    "    :param date_column: Column with date of article\n",
    "    :param abstract_column: Abstract Column\n",
    "    :param covid_terms: List of covid terms to be used as a regular expression\n",
    "    :return: Spark Dataframe with new boolean column\n",
    "    \"\"\"\n",
    "    if covid_terms is None:\n",
    "        covid_terms = ['covid', 'sars-?n?cov-?2', '2019-ncov', 'novel coronavirus', 'sars coronavirus 2']\n",
    "\n",
    "    covid_search = f\".*({'|'.join(covid_terms)})\"\n",
    "\n",
    "    since_covid = ((col(date_column) > SARS_COV_2_DATE) | (isnull(col(date_column))))\n",
    "    covid_term_match = since_covid | col(abstract_column).rlike(covid_search)\n",
    "    wuhan_outbreak = since_covid & col(abstract_column).rlike('.*(wuhan|hubei)')\n",
    "    covid_match = covid_term_match | wuhan_outbreak\n",
    "    spark_df = spark_df.withColumn('covid_related', coalesce(covid_match, lit(False)))\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = tag_covid(spark_df=df)\n",
    "df = tag_virus(spark_df=df)\n",
    "df = tag_coronavirus(spark_df=df)\n",
    "df = tag_sars(spark_df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df.toPandas().head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Formatting dates and Filling Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def format_date(spark_df: SparkDataframe, date_column='publish_time') -> SparkDataframe:\n",
    "    \"\"\"\n",
    "    Formats date column to a single format\n",
    "    :param spark_df: Spark Dataframe\n",
    "    :param date_column: Column to be formatted\n",
    "    :return: Dataframe with formatted dates column\n",
    "    \"\"\"\n",
    "    spark_df = spark_df.withColumn(date_column, when(isnull(col(date_column)), '').\n",
    "                                   otherwise(to_date(col(date_column))))\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def fill_nulls(spark_df: SparkDataframe,\n",
    "               columns=['authors', 'abstract']) -> SparkDataframe:\n",
    "    \"\"\"\n",
    "    Fill columns with null values\n",
    "    :param spark_df: Spark Dataframe\n",
    "    :return: Spark Dataframe with empty string instead of None\n",
    "    \"\"\"\n",
    "    return spark_df.na.fill('', columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = format_date(spark_df=df)\n",
    "df = fill_nulls(spark_df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Running Spark Jobs on EMR Serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The above spark job will run on EMR Serverless. The AWS Service works similarly to lambda, where you only pay for the amount of processing/storage used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The main advantage is that there is not requirement to set up clusters and, therefore, pay for idle time. This makes EMR Serverless ideal to ad-hoc jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Setting up Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to run EMR Serverless we need to:\n",
    "\n",
    "- Upload our locally created modules to AWS so our Spark Job can access them\n",
    "- Upload our Python Virtual Environment with any custom frameworks we may require\n",
    "- Upload our data to S3 so it is accessible by the Spark Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Change Variables below to reflect your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_PROFILE = 'projectpro'\n",
    "AWS_REGION = 'us-east-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "S3_BUCKET = 'project-pro-emr-serverless123'\n",
    "S3_LOGS_BUCKET = f'projectpro-emr-serverless-logs'\n",
    "aws_access_key_id = 'Enter your access key id'\n",
    "aws_secret_access_key = 'Enter your secret key'\n",
    "APPLICATION_ID = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### We need to create a EMR Role to be used by the submitted jobs, you can create a role with the following rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "EMR_JOB_ROLE_ARN = 'arn:aws:iam::143176219551:role/emr-new-role'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "APPLICATION_NAME = 'COVID19'\n",
    "\n",
    "DEFAULT_INPUT_PATH = f's3://{S3_BUCKET}/data'\n",
    "S3_OUT_PATH = f's3://{S3_BUCKET}/out/'\n",
    "DEFAULT_INPUT_FORMAT = 'csv'\n",
    "\n",
    "UPDATE_ENVIRONMENT = False\n",
    "UPDATE_MODULES = True\n",
    "\n",
    "ENVIRONMENT_PATH = f's3://{S3_BUCKET}/environment'\n",
    "ENVIRONMENT_FILE = 'environment.tar.gz'\n",
    "FULL_ENVIRONMENT_PATH = f'{ENVIRONMENT_PATH}/{ENVIRONMENT_FILE}'\n",
    "\n",
    "MODULE_PATH = f's3://{S3_BUCKET}/modules'\n",
    "MODULE_FILE = 'src.zip'\n",
    "FULL_MODULE_PATH = f'{MODULE_PATH}/{MODULE_FILE}'\n",
    "\n",
    "SCRIPT_PATH = f's3://{S3_BUCKET}/scripts'\n",
    "SCRIPT_FILE = 'spark_job.py'\n",
    "FULL_SCRIPT_PATH = f'{SCRIPT_PATH}/{SCRIPT_FILE}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=AWS_REGION,aws_access_key_id=aws_access_key_id,aws_secret_access_key=aws_secret_access_key)\n",
    "client = session.client(\"emr-serverless\", region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Creating Virtual Environment using Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The virtual environment we are going to upload needs to be created by an Amazon Linux image, otherwise it won't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We use a docker image with the below command to create an ``environment.tar.gz`` in our folder which is going to be uploaded to s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "``docker build --output . .``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Uploading required files to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "if UPDATE_MODULES:\n",
    "    if os.path.isfile(MODULE_FILE):\n",
    "        os.remove(MODULE_FILE)\n",
    "\n",
    "    if SCRIPT_FILE is not None and SCRIPT_PATH is not None:\n",
    "        module_file_name = MODULE_FILE.split('.')[0]\n",
    "        module_file_extension = MODULE_FILE.split('.')[1]\n",
    "        filename = f'{module_file_name}.{module_file_extension}'\n",
    "        shutil.make_archive('src', 'zip', '../', 'src')\n",
    "        wrangler.s3.upload(SCRIPT_FILE, FULL_SCRIPT_PATH, boto3_session=session)\n",
    "        wrangler.s3.upload(MODULE_FILE, FULL_MODULE_PATH, boto3_session=session)\n",
    "\n",
    "if UPDATE_ENVIRONMENT:\n",
    "    if not os.path.isfile(f'../{ENVIRONMENT_FILE}'):\n",
    "        raise Exception('Build your environment first using Docker: '\n",
    "                        'DOCKER_BUILDKIT=1 docker build --output . .')\n",
    "\n",
    "    wrangler.s3.upload(f'../{ENVIRONMENT_FILE}', FULL_ENVIRONMENT_PATH, boto3_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and starting EMR Serverless Spark App\n"
     ]
    }
   ],
   "source": [
    "# Create and start a new EMRServerless Spark Application\n",
    "emr_serverless = EMRServerless(emr_client=client, application_id=APPLICATION_ID)\n",
    "print(f\"Creating and starting EMR Serverless Spark App\")\n",
    "emr_serverless.create_application(APPLICATION_NAME, \"emr-6.6.0\")\n",
    "emr_serverless.start_application()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "files = wrangler.s3.list_objects(f'{DEFAULT_INPUT_PATH}', boto3_session=session)\n",
    "job_dict = {}\n",
    "job_run_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running a total of 1 EMR Serverless Jobs\n",
      "Submitting new Spark job num 0 and id 00f76fursoe2b209\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running a total of {len(files)} EMR Serverless Jobs\")\n",
    "\n",
    "for ix, file in enumerate(sorted(files)):\n",
    "    # Submit a Spark job\n",
    "    try:\n",
    "        job_run_id = emr_serverless.run_spark_job(\n",
    "            name=APPLICATION_NAME,\n",
    "            script_location=f\"{FULL_SCRIPT_PATH}\",\n",
    "            venv_name=\"environment\",\n",
    "            venv_location=f'{FULL_ENVIRONMENT_PATH}',\n",
    "            modules_location=f'{FULL_MODULE_PATH}',\n",
    "            job_role_arn=EMR_JOB_ROLE_ARN,\n",
    "            arguments=[\"PROD\", file, DEFAULT_INPUT_FORMAT, S3_OUT_PATH],\n",
    "            s3_bucket_name=S3_LOGS_BUCKET,\n",
    "            wait=False\n",
    "        )\n",
    "        print(f\"Submitting new Spark job num {ix} and id {job_run_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error while submitting job: \\n{e}')\n",
    "\n",
    "        for job_run_id in job_dict.keys():\n",
    "            job_status = emr_serverless.cancel_spark_job(job_id=job_run_id)\n",
    "            print(f'Job {job_run_id} cancelled')\n",
    "\n",
    "        raise e\n",
    "\n",
    "    job_dict[job_run_id] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 1,\n",
      "Jobs Completed 0,\n",
      "Jobs Failed 0\n",
      "----\n",
      "Jobs Running 0,\n",
      "Jobs Completed 1,\n",
      "Jobs Failed 0\n",
      "Done! 👋\n"
     ]
    }
   ],
   "source": [
    "all_done = False\n",
    "jobs_completed = 0\n",
    "jobs_running = len(job_dict.keys())\n",
    "jobs_failed = 0\n",
    "\n",
    "while not all_done:\n",
    "\n",
    "    for job_id in job_dict.keys():\n",
    "        job_status = emr_serverless.get_job_run(job_id)\n",
    "        job_done = job_status.get(\"state\") in [\n",
    "            \"SUCCESS\",\n",
    "            \"FAILED\",\n",
    "            \"CANCELLING\",\n",
    "            \"CANCELLED\",\n",
    "        ]\n",
    "\n",
    "        if job_done:\n",
    "            job_dict[job_id] = True\n",
    "            job_state = job_status.get(\"state\")\n",
    "\n",
    "            if job_state == \"SUCCESS\":\n",
    "                jobs_completed += 1\n",
    "\n",
    "            if job_state == \"FAILED\":\n",
    "                jobs_failed += 1\n",
    "\n",
    "            jobs_running -= 1\n",
    "            all_done = all(job_dict.values())\n",
    "\n",
    "        print(f\"Jobs Running {jobs_running},\"\n",
    "              f\"\\nJobs Completed {jobs_completed},\"\n",
    "              f\"\\nJobs Failed {jobs_failed}\")\n",
    "\n",
    "    if all_done:\n",
    "        break\n",
    "\n",
    "    print('----')\n",
    "\n",
    "    time.sleep(20)\n",
    "\n",
    "print(\"Done! 👋\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Data with Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM covid19_emr_1out limit 10000\"\n",
    "athena_df = wrangler.athena.read_sql_query(sql, database='default', boto3_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_time</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>covid_related</th>\n",
       "      <th>virus_related</th>\n",
       "      <th>corona_related</th>\n",
       "      <th>sars_related</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>Neurological Complications of Coronavirus Dise...</td>\n",
       "      <td>Coronavirus disease 2019 (COVID-19) is a pande...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://doi.org/10.7759/cureus.7352; https://w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>Myeloid-derived suppressor cells in COVID-19: ...</td>\n",
       "      <td>Coronavirus disease 2019 (COVID-19) is a poten...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/pubmed/35489643/;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>Clinical significance of measuring serum cytok...</td>\n",
       "      <td>Coronavirus disease 2019 (COVID-19) is a rapid...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>Therapeutic approaches and vaccination in figh...</td>\n",
       "      <td>Coronavirus disease 2019 (COVID-19) is a remar...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>https://doi.org/10.1016/j.genrep.2022.101619; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Arterial Thrombosis in an Asymptomatic COVID-1...</td>\n",
       "      <td>Coronavirus disease 2019 (COVID-19) is a sever...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_time                                              title  \\\n",
       "0   2020-03-21  Neurological Complications of Coronavirus Dise...   \n",
       "1   2022-04-27  Myeloid-derived suppressor cells in COVID-19: ...   \n",
       "2   2021-02-23  Clinical significance of measuring serum cytok...   \n",
       "3   2022-05-04  Therapeutic approaches and vaccination in figh...   \n",
       "4   2021-01-01  Arterial Thrombosis in an Asymptomatic COVID-1...   \n",
       "\n",
       "                                            abstract  covid_related  \\\n",
       "0  Coronavirus disease 2019 (COVID-19) is a pande...           True   \n",
       "1  Coronavirus disease 2019 (COVID-19) is a poten...           True   \n",
       "2  Coronavirus disease 2019 (COVID-19) is a rapid...           True   \n",
       "3  Coronavirus disease 2019 (COVID-19) is a remar...           True   \n",
       "4  Coronavirus disease 2019 (COVID-19) is a sever...           True   \n",
       "\n",
       "   virus_related  corona_related  sars_related  \\\n",
       "0           True           False         False   \n",
       "1           True           False         False   \n",
       "2           True            True         False   \n",
       "3           True            True         False   \n",
       "4           True            True         False   \n",
       "\n",
       "                                                 url  \n",
       "0  https://doi.org/10.7759/cureus.7352; https://w...  \n",
       "1  https://www.ncbi.nlm.nih.gov/pubmed/35489643/;...  \n",
       "2  https://www.sciencedirect.com/science/article/...  \n",
       "3  https://doi.org/10.1016/j.genrep.2022.101619; ...  \n",
       "4                                               <NA>  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athena_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the BM25 index from the abstracts of the papers\n",
      "Use index=\"text\" if you want to index the texts of the paper instead\n",
      "Finished Indexing in 44.0 seconds\n"
     ]
    }
   ],
   "source": [
    "bm25_index = engine.BM25SearchEngine(athena_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       " <h4 class='cord'>The impact of atherosclerotic cardiovascular disease, dyslipidaemia and lipid lowering therapy on Coronavirus disease 2019 outcomes: an examination of the available evidence</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-01-01</span>\n",
       "     <a href='<NA>' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>12.6</span>\n",
       " </div>\n",
       " <div class='abstract'>Conversely, pleiotropic effects of statins can theoretically protect against severe COVID19 infection, supporting evidence from other respiratory illnesses in which statin use probably confers benefit.\n",
       "RECENT FINDINGS: There is an abundance of studies that show that statins are safe and potentially protect against severe COVID19 infection (critical illness and death), even when adjustment for potential confounders is undertaken.\n",
       "Available clinical guidelines recommend the ongoing use of LLT in p...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>COVID19 infection in a patient with paroxysmal nocturnal hemoglobinuria: A case report</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-05-21</span>\n",
       "     <a href='https://doi.org/10.1097/md.0000000000025456; https://www.ncbi.nlm.nih.gov/pubmed/34011023/' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>12.4</span>\n",
       " </div>\n",
       " <div class='abstract'>PATIENT CONCERNS: A 27-year-old Caucasian man with PNH presented to the Emergency Department of our hospital with acute onset shortness of breath, cough and blood in urine.\n",
       "DIAGNOSIS: The patient was diagnosed with acute hemolytic exacerbation of PNH complicated with moderate COVID19 pneumonia.\n",
       "CONCLUSION: The complement system activation is a critical component in the sequalae of COVID19 infection.\n",
       "Evidence suggests that severe outcomes in COVID19 infection are attributed to the excessive activ...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Coronavirus case presentation in a patient with loss of consciousness due to dyspnea</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-10-30</span>\n",
       "     <a href='https://www.sciencedirect.com/science/article/pii/S2049080121009444; https://doi.org/10.1016/j.amsu.2021.102994; https://www.ncbi.nlm.nih.gov/pubmed/34745604/; https://api.elsevier.com/content/article/pii/S2049080121009444' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>10.9</span>\n",
       " </div>\n",
       " <div class='abstract'>AND IMPORTANCE: Severity of corona virus disease 2019 (COVID19) is presented with respiratory distress.\n",
       "CASE PRESENTATION: We present a case of a 29-year-old male who was not presented with typical symptoms of COVID19 at the time of referral but loss of consciousness.\n",
       "CLINICAL DISCUSSION: The importance of testing patients without typical symptoms for coronavirus infection and multi-system manifestation of the virus is presented in this case.\n",
       "CONCLUSION: Severe drop in oxygen saturation in asymp...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Delayed positive COVID19 nasopharyngeal test, a case study with clinical and pathological correlation</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-08-31</span>\n",
       "     <a href='https://doi.org/10.1186/s12890-021-01643-y; https://www.ncbi.nlm.nih.gov/pubmed/34465321/' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>10.5</span>\n",
       " </div>\n",
       " <div class='abstract'>CASE PRESENTATION: A 64-year-old male with history of pulmonary fungal infection, asthma and chronic pulmonary obstructive disease (COPD), diabetes, coronary artery disease presented with shortness of breath, fever and chest image of ground opacity, reticular interstitial thickening, highly suspicious for COVID19.\n",
       "One week later, repeated COVID19 nasopharyngeal tests on day 40 and day 49 became positive.\n",
       "CONCLUSION: Our case and literature review indicate that allergic asthma and associated high...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Mutations and polymorphisms in genes involved in the infections by covid 19: a review</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-02-25</span>\n",
       "     <a href='https://www.ncbi.nlm.nih.gov/pubmed/33655087/; https://doi.org/10.1016/j.genrep.2021.101062; https://www.sciencedirect.com/science/article/pii/S2452014421000479?v=s5; https://api.elsevier.com/content/article/pii/S2452014421000479' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>10.3</span>\n",
       " </div>\n",
       " <div class='abstract'>In addition to these elements, genetic factors have an important role in Covid19 infection.\n",
       "Interindividual variation in susceptibility to infection by Covid-19 has been associated with to the presence of genetic polymorphisms in many genes, especially in those that code for proteins implicated in the infection process.\n",
       "The present review gives a brief overview of different genes involved in the infection by SARS-CoV-2 and its association with disease severity.\n",
       "The results of our research showed...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Generating Realistic COVID19 X-rays with a Mean Teacher + Transfer Learning GAN</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2020-01-01</span>\n",
       "     <a href='<NA>' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>9.7</span>\n",
       " </div>\n",
       " <div class='abstract'>We present a novel Mean Teacher + Transfer GAN (MTT-GAN) that generates COVID19 chest X-ray images of high quality.\n",
       "In order to create a more accurate GAN, we employ transfer learning from the Kaggle Pneumonia X-Ray dataset, a highly relevant data source orders of magnitude larger than public COVID19 datasets.\n",
       "Our qualitative analysis shows that the MTT-GAN generates X-ray images that are greatly superior to a baseline GAN and visually comparable to real X-rays.\n",
       "Quantitative analysis shows that ...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>The pattern of COVID 19 pandemic among patients with autoimmune inflammatory rheumatic diseases (AIIRD)</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-01-01</span>\n",
       "     <a href='https://doi.org/10.1136/annrheumdis-2021-eular.2581' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>9.2</span>\n",
       " </div>\n",
       " <div class='abstract'>The registry included demographic data, AIIRD diagnosis and duration, systemic organ involvement, co-morbidities, treatment (conventional synthetic disease modifying drugs (csDMARDs), biologic/targeted (b/ts) DMARDs, corticosteroids use, dose and treatment duration, date of COVID19 diagnosis, severity of the viral disease and complications, duration of hospitalization, if required, treatment for COVID 19, laboratory results and outcome.\n",
       "The epidemiological data regarding the number of COVID19 co...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Herpes Zoster (shingles) complicating the course of COVID19 infection.</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2020-06-16</span>\n",
       "     <a href='https://doi.org/10.1080/09546634.2020.1782823; https://www.ncbi.nlm.nih.gov/pubmed/32543328/' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>8.8</span>\n",
       " </div>\n",
       " <div class='abstract'>Different skin presentations and patterns of cutaneous signs were reported in COVID19 patients.\n",
       "Varicella-zoster virus (VZV) infection is responsible for two very common skin conditions.\n",
       "Varicella (chichkenpox) is the initial presentation for infection with VZV and is characterized by a diffuse vesicular rash.\n",
       "It is after this initial attack, that VZV remains latent in the dorsal root ganglia before reactivating to present as herpes zoster (HZ) in middle age groups.\n",
       "Cutaneous skin findings remai...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>On economy, health and politics of the Covid19 pandemic</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2020-01-01</span>\n",
       "     <a href='<NA>' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>8.8</span>\n",
       " </div>\n",
       " <div class='abstract'>On economy, health and politics of the Covid19 pandemic</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Editorial: COVID19 Vaccination in Frail People. Lots of Hope and Some Questions</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-01-01</span>\n",
       "     <a href='<NA>' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>8.6</span>\n",
       " </div>\n",
       " <div class='abstract'>Editorial: COVID19 Vaccination in Frail People. Lots of Hope and Some Questions</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       "\n",
       "<style>\n",
       ".authors{\n",
       "    margin: 4px 0px 15px;\n",
       "}\n",
       ".authors { color: #778899}\n",
       ".published {color: #2F4F4F; font-weight: bold; font-size: 0.9em; margin-right: 10px}\n",
       "#cord_uid{margin-left: 10px; font-weight: bold; font-size: 0.9em;}\n",
       "h2.cord, h3.cord, h4.cord {margin: 15px 0px 8px 0px}\n",
       "h4.cord{color:#008B8B; font-size: 1.1em; margin-top: 25px}\n",
       "div.abstract { margin: 10px 0px 2px}\n",
       "div#pubished_when{margin: 10px; display: block}\n",
       ".link-text {color: #808080; font-size: 0.9em}\n",
       "</style>"
      ],
      "text/plain": [
       "<src.search.results.SearchResults at 0x248caeb0610>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.SearchResults(bm25_index.search('COVID19 Infection')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       " <h4 class='cord'>Delayed positive COVID19 nasopharyngeal test, a case study with clinical and pathological correlation</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-08-31</span>\n",
       "     <a href='https://doi.org/10.1186/s12890-021-01643-y; https://www.ncbi.nlm.nih.gov/pubmed/34465321/' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>12.4</span>\n",
       " </div>\n",
       " <div class='abstract'>CASE PRESENTATION: A 64-year-old male with history of pulmonary fungal infection, asthma and chronic pulmonary obstructive disease (COPD), diabetes, coronary artery disease presented with shortness of breath, fever and chest image of ground opacity, reticular interstitial thickening, highly suspicious for COVID19.\n",
       "One week later, repeated COVID19 nasopharyngeal tests on day 40 and day 49 became positive.\n",
       "CONCLUSION: Our case and literature review indicate that allergic asthma and associated high...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>The impact of atherosclerotic cardiovascular disease, dyslipidaemia and lipid lowering therapy on Coronavirus disease 2019 outcomes: an examination of the available evidence</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-01-01</span>\n",
       "     <a href='<NA>' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>11.5</span>\n",
       " </div>\n",
       " <div class='abstract'>Conversely, pleiotropic effects of statins can theoretically protect against severe COVID19 infection, supporting evidence from other respiratory illnesses in which statin use probably confers benefit.\n",
       "RECENT FINDINGS: There is an abundance of studies that show that statins are safe and potentially protect against severe COVID19 infection (critical illness and death), even when adjustment for potential confounders is undertaken.\n",
       "Available clinical guidelines recommend the ongoing use of LLT in p...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Graph Analytics Applied to COVID19 Karnataka State Dataset</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'><NA></span>\n",
       "     <a href='Abhilash, C.; Mahesh, K.' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>10.9</span>\n",
       " </div>\n",
       " <div class='abstract'>\"The coronavirus pandemic, or COVID19, has emerged as a pandemic.\n",
       "Handling this pandemic situation is a fundamental challenge to the concerned authorities.\n",
       "However, not all states of India have had the same position or spread counts.\n",
       "The significant impact was from Lockdown 1.0, which controlled the growth of the exponential curve.\n",
       "Here we have considered the Karnataka state data referring to the Ministry of Health and Family welfare department, GoK.\n",
       "This paper presents a case study on the state...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Coronavirus case presentation in a patient with loss of consciousness due to dyspnea</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-10-30</span>\n",
       "     <a href='https://www.sciencedirect.com/science/article/pii/S2049080121009444; https://doi.org/10.1016/j.amsu.2021.102994; https://www.ncbi.nlm.nih.gov/pubmed/34745604/; https://api.elsevier.com/content/article/pii/S2049080121009444' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>10.8</span>\n",
       " </div>\n",
       " <div class='abstract'>AND IMPORTANCE: Severity of corona virus disease 2019 (COVID19) is presented with respiratory distress.\n",
       "CASE PRESENTATION: We present a case of a 29-year-old male who was not presented with typical symptoms of COVID19 at the time of referral but loss of consciousness.\n",
       "CLINICAL DISCUSSION: The importance of testing patients without typical symptoms for coronavirus infection and multi-system manifestation of the virus is presented in this case.\n",
       "CONCLUSION: Severe drop in oxygen saturation in asymp...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Generating Realistic COVID19 X-rays with a Mean Teacher + Transfer Learning GAN</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2020-01-01</span>\n",
       "     <a href='<NA>' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>9.7</span>\n",
       " </div>\n",
       " <div class='abstract'>We present a novel Mean Teacher + Transfer GAN (MTT-GAN) that generates COVID19 chest X-ray images of high quality.\n",
       "In order to create a more accurate GAN, we employ transfer learning from the Kaggle Pneumonia X-Ray dataset, a highly relevant data source orders of magnitude larger than public COVID19 datasets.\n",
       "Our qualitative analysis shows that the MTT-GAN generates X-ray images that are greatly superior to a baseline GAN and visually comparable to real X-rays.\n",
       "Quantitative analysis shows that ...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>COVID19 infection in a patient with paroxysmal nocturnal hemoglobinuria: A case report</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-05-21</span>\n",
       "     <a href='https://doi.org/10.1097/md.0000000000025456; https://www.ncbi.nlm.nih.gov/pubmed/34011023/' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>9.6</span>\n",
       " </div>\n",
       " <div class='abstract'>PATIENT CONCERNS: A 27-year-old Caucasian man with PNH presented to the Emergency Department of our hospital with acute onset shortness of breath, cough and blood in urine.\n",
       "DIAGNOSIS: The patient was diagnosed with acute hemolytic exacerbation of PNH complicated with moderate COVID19 pneumonia.\n",
       "CONCLUSION: The complement system activation is a critical component in the sequalae of COVID19 infection.\n",
       "Evidence suggests that severe outcomes in COVID19 infection are attributed to the excessive activ...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Mutations and polymorphisms in genes involved in the infections by covid 19: a review</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-02-25</span>\n",
       "     <a href='https://www.ncbi.nlm.nih.gov/pubmed/33655087/; https://doi.org/10.1016/j.genrep.2021.101062; https://www.sciencedirect.com/science/article/pii/S2452014421000479?v=s5; https://api.elsevier.com/content/article/pii/S2452014421000479' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>9.5</span>\n",
       " </div>\n",
       " <div class='abstract'>In addition to these elements, genetic factors have an important role in Covid19 infection.\n",
       "Interindividual variation in susceptibility to infection by Covid-19 has been associated with to the presence of genetic polymorphisms in many genes, especially in those that code for proteins implicated in the infection process.\n",
       "The present review gives a brief overview of different genes involved in the infection by SARS-CoV-2 and its association with disease severity.\n",
       "The results of our research showed...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>COVID-19: Impact of Obesity and Diabetes in Disease Severity</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2020-05-26</span>\n",
       "     <a href='http://medrxiv.org/cgi/content/short/2020.05.24.20111724v1?rss=1; https://doi.org/10.1101/2020.05.24.20111724' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>9.4</span>\n",
       " </div>\n",
       " <div class='abstract'>Background: The Coronavirus disease 2019 (COVID19) pandemic is straining the healthcare system, particularly for patients with severe outcomes who require admittance to the intensive care unit (ICU).\n",
       "Results: From the 1158 hospitalized patients, 271 (23.4%) had diabetes, 236 (20.4%) had hypertension and 104 (9%) required admittance into the ICU.\n",
       "Two models for multivariate regression analysis were used, assessing either BMI or diabetes on ICU outcomes.\n",
       "In the BMI model, class I obesity and morbi...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>The pattern of COVID 19 pandemic among patients with autoimmune inflammatory rheumatic diseases (AIIRD)</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-01-01</span>\n",
       "     <a href='https://doi.org/10.1136/annrheumdis-2021-eular.2581' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>9.2</span>\n",
       " </div>\n",
       " <div class='abstract'>The registry included demographic data, AIIRD diagnosis and duration, systemic organ involvement, co-morbidities, treatment (conventional synthetic disease modifying drugs (csDMARDs), biologic/targeted (b/ts) DMARDs, corticosteroids use, dose and treatment duration, date of COVID19 diagnosis, severity of the viral disease and complications, duration of hospitalization, if required, treatment for COVID 19, laboratory results and outcome.\n",
       "The epidemiological data regarding the number of COVID19 co...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       " <h4 class='cord'>Impact of COVID-19 on acute ischemic stroke care at henry ford Hospital's Detroit and West Bloomfield Campuses</h4>\n",
       " <div id=\"published_when\">\n",
       "     <span class='published'>2021-01-01</span>\n",
       "     <a href='<NA>' rel=\"noopener noreferrer\" target=\"_blank\" class='link'>Link</a> <span id='Score'>8.9</span>\n",
       " </div>\n",
       " <div class='abstract'>Background: Coronavirus 2019 (COVID19) has impacted acute stroke (AS) care with several reports globally showing drops in AS volumes during the pandemic We studied the impact of COVID19 on AS and transient ischemic attack (TIA) care in a health system serving Southeast Michigan as we rolled out a policy aimed at limiting admissions and transfers Methods: In this retrospective study conducted at 2 hospitals, we included consecutive patients presenting to the emergency department (ED) for whom a S...</div>\n",
       " <div class='authors'></div>\n",
       "\n",
       "\n",
       "\n",
       "<style>\n",
       ".authors{\n",
       "    margin: 4px 0px 15px;\n",
       "}\n",
       ".authors { color: #778899}\n",
       ".published {color: #2F4F4F; font-weight: bold; font-size: 0.9em; margin-right: 10px}\n",
       "#cord_uid{margin-left: 10px; font-weight: bold; font-size: 0.9em;}\n",
       "h2.cord, h3.cord, h4.cord {margin: 15px 0px 8px 0px}\n",
       "h4.cord{color:#008B8B; font-size: 1.1em; margin-top: 25px}\n",
       "div.abstract { margin: 10px 0px 2px}\n",
       "div#pubished_when{margin: 10px; display: block}\n",
       ".link-text {color: #808080; font-size: 0.9em}\n",
       "</style>"
      ],
      "text/plain": [
       "<src.search.results.SearchResults at 0x248cc7fedf0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.SearchResults(bm25_index.search('Are COVID19 and Coronavirus related?')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
